{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEYDm_ICb4GC"
      },
      "source": [
        "# ORIE 4580/5580/5581 Assignment 5\n",
        "\n",
        "#### Students: S. Ulam (su001) and J. von Neuman (jvn001)\n",
        "\n",
        "### Github link: [example Github link](https://github.com/SidBanerjee/ORIE4580-Simulation/blob/main/Notebooks/Unit0-Intro_Demos.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "\n",
        "* Due Friday, October 13, at 11.59am on Gradescope.\n",
        "* Assignment .ipynb files available for download on [Canvas](https://canvas.cornell.edu/courses/56826#:~:text=Assignments-,Assignments,-Assignments%20Module%20publish). Do all your work in provided notebook (text answers typeset in markdown; show all required code and generate plots inline), and then generate and submit a pdf.\n",
        "* Ideally do assignments in groups of 2, and submit a single pdf with both names\n",
        "* Please show your work and clearly mark your answers.\n",
        "* You can use any code fragments given in class, found online (for example, on StackOverflow), or generated via Bard or ChatGPT (you are encouraged to use these for first drafts) **with proper referencing**. You can also discuss with others (again, please reference them if you do so); but you must write your final answers on your own as a team.\n",
        "\n",
        "\n",
        "\n",
        "### Suggested reading\n",
        "\n",
        "Chapters 8 (all parts) and 9 (up to Section 9.2 for the midterm) of [Simulation by Ross](https://catalog.library.cornell.edu/catalog/12745977)."
      ],
      "metadata": {
        "id": "l3G_wUFRg9v6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "# Question 1: Red-Tailed Hawks! (15 points)\n",
        "\n",
        "(Dedicated to [Big Red and Arthur](https://www.youtube.com/watch?v=diIn5tc8AJo), and their amazing family!)\n",
        "\n",
        "A School of Ornithology researcher wants to estimate the number of red-tailed hawks in Ithaca. She radio tags 10 birds, and then sets up a feeding station with automatic camera.\n",
        "\n",
        "The researcher believes that each individual bird's visits to the feeder can be modeled as a *Poisson process* with some unknown rate $\\lambda$; we will talk more about the Poisson process in detail later in the semester (for a quick refresher, see Section 2.9.4 of Ross), but for this question, the main thing you need to know is that this is a process that counts a discrete number of arrivals, where the *inter-arrival* between one arrival and the next is independent and identically distributed as an Exponential$(\\lambda)$ random variable (similar to the trains in question 5b in the previous assignment).\n",
        "\n",
        "**(a)**\n",
        "Over the first five weeks, the researcher observes an average of 28.8 birds (tagged and untagged) visiting the feeder, with an average of 6 tagged birds per week. Use the method of moments to obtain an estimate for the total population."
      ],
      "metadata": {
        "id": "5AMJpIgg0AUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "## Ans.\n"
      ],
      "metadata": {
        "id": "FdZFPY8J00Nz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "**(b)** Next, the researcher develops a video processing program which can identify and distinguish different individual birds from their pictures. Using this, over the next week, she observes 20 unique birds visiting the feeding station, out of which 4 are tagged. What is the MLE for the size of the hawk population in Ithaca?\n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "kHPnqRj105lL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans.\n",
        "\n"
      ],
      "metadata": {
        "id": "o-b5c59b2CV-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mT-3ogKx2Hzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX0Mw-EVb4GE"
      },
      "source": [
        "___\n",
        "___\n",
        "\n",
        "# Question 2: Soup for Lunch? (15 points)\n",
        "\n",
        "The folks at the [Temple of Zeus](https://as.cornell.edu/about/temple-of-zeus) have the best soup offerings at Cornell -- however, by the time you are done with Simulation, they often run out of soup. To remedy this, you want to try and understand the demand for soup, so that you can suggest how much they should make. You decide to model the total demand $N$ for soups each day as a geometric random variable with parameter $p$ (i.e., $P(N = k) = (1-p)^kp$, $k \\ge 0$).\n",
        "\n",
        "The Temple of Zeus manager gives you data for the number of lunches sold in the last $100$ days. One problem though is that the data is *censored*: the staff prepared soup for at most $40$ servings each day, and as a result, the number of sales each day is between 0 and 40. As a result, on days when the number of soups sold is $40$, you cannot be sure what the true demand $N_i$ was (but you know $N_i\\geq 40$); on other days, the number of soups sold is the true demand $N_i<40$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjy3dHqpb4GF"
      },
      "source": [
        "___\n",
        "\n",
        "**(a)**\n",
        "What is the probability mass function of the per-day sales $Y$ in terms of $p$?\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOQnI769b4GF"
      },
      "source": [
        "## Ans.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRpHC9hbb4GF"
      },
      "source": [
        "___\n",
        "\n",
        "**(b)** Compute a maximum likelihood estimator of $p$ based on the sales data for soup given in `Soup_sales_data.csv`.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1khe5-56b4GF"
      },
      "source": [
        "## Ans.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00N4KuJqlEHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "___\n",
        "\n",
        "# Question 3: The Birthday Paradox (40 pts)\n",
        "\n",
        "In this question, we investigate the celebrated [birthday paradox](https://en.wikipedia.org/wiki/Birthday_problem)!"
      ],
      "metadata": {
        "id": "Lh-UW13FuhSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "**(a)** The basic question you may have seen in earlier probability courses is the following: given a party of $n$ people whose birthdays are drawn uniformly over the $365$ days in the year, what is the probability that at least two people share a birthday. Derive an expression for the probability, and plot it for $n\\in\\{10,11,12,\\ldots,49,50\\}$.\n",
        "___"
      ],
      "metadata": {
        "id": "yc0A7WxsuyEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans."
      ],
      "metadata": {
        "id": "EGsUT8JvwI-7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CGZf5O0Kx9Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "**(b)** Next, we want to obtain the above probabilities by simulation. For a given $n$, perform simulations so as to estimate the probability  of at least two people sharing birthdays in a group of $n$, for $n\\in\\{15,16,\\ldots,30\\}$, up to $2$ decimal places (with $95\\%$ confidence). Plot the estimates and $95\\%$ CI, and also plot the theoretical result from part $(a)$ in the same plot.\n",
        "___"
      ],
      "metadata": {
        "id": "QhBwTPrLwKhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans."
      ],
      "metadata": {
        "id": "_u8ikVrMx664"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L9gMbHO2x8cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**(c)** One flaw in our analysis is that birth-dates may not be uniformly distributed throughout the year. To check this, we can look at data of real birth-dates.\n",
        "\n",
        "The file `bdaydata.txt` has a list of $365$ days in the year (excluding February $29$) and the corresponding number of birthdays on that date. Load the dataset and plot the following:\n",
        "\n",
        "i. Empirical histogram of the data\n",
        "\n",
        "ii. Empirical cdf\n",
        "\n",
        "iii. Q-Q plot comparing the data to a uniform distribution\n",
        "\n",
        "(Dataset based on life insurance data from 1981-94; data and example courtesy [Roy Murphy](http://www.panix.com/~murphy/bday.html).)\n",
        "___"
      ],
      "metadata": {
        "id": "fT4Jt0Inx99q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans."
      ],
      "metadata": {
        "id": "g4c_Csc_ywpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For loading the data, you can use \"df = pd.read_csv('bdaydata.txt',sep=' ')\"\n",
        "# Please note that the txt file needs to be placed in the same folder with the ipynb file.\n",
        "# To extract the counts column as a vector, use \"df.values[:,1]\""
      ],
      "metadata": {
        "id": "NkcHgFB4yy41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "**(d)** Perform a Chi-square Test **and** a Kolmogorov-Smirnov Test to study how well the data is modeled by a uniform distribution.\n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "4983wTTlkaG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans.\n"
      ],
      "metadata": {
        "id": "0dWUUfznkl5k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3XLVod3kuIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "**(e)** Since you have an extensive dataset of birthday frequency, you can directly use the nonparametric bootstrap to estimate the probability of at least two people sharing birthdays in a group of $n$. Plot the bootstrap estimate and $95\\%$ CI for $n\\in\\{15,16,\\ldots,30\\}$, and compare against the plot in part $(b)$.\n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "ga-5b3SSkoKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans.\n"
      ],
      "metadata": {
        "id": "puJK5Zkio3RD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Th2tmBoo5Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJhVnfbFb4GI"
      },
      "source": [
        "___\n",
        "___\n",
        "\n",
        "# Question 4: Benford's Law (30 pts)\n",
        "\n",
        "In this question, we will use the Chi-square test to study *Benford's law* in a variety of setttings. Consider a data set consisting of $n$ different numbers, and look at the leading digit of each number (for example, the leading digit of $123.456$ is $1$, and the leading digit of $-0.423$ is $4$). For many data sets, the fraction of leading digits that equal $1$ is much higher than $1/9$ (i.e., what it would be if uniformlly distributed); in fact, the probability distribution of the different leading digits $1, 2, \\ldots, 9$ is far from uniform.\n",
        "\n",
        "This observation has been observed to hold in measurements of distances to galaxies, numbers appearing in tax forms and many other settings, and has been used to detect fraud among other uses. See [the Wikipedia page](https://en.wikipedia.org/wiki/Benford\\%27s_law) for a description of this phenomena, and [this blog post](https://terrytao.wordpress.com/2009/07/03/benfords-law-zipfs-law-and-the-pareto-distribution/) for an interesting related discussion. More recently, this has also been (supposedly) misused in (supposedly) detecting (supposed) fraud in election results -- see [this Stand-Up Maths](https://www.youtube.com/watch?v=etx0k1nLn78&t=4s) video for a great example of how data analysis should be done!\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCLoBig-b4GI"
      },
      "source": [
        "___\n",
        "\n",
        "**(a)** First, we will study this phenomena in a *synthetic* dataset. For this, compute the first digits of $n!$ for the first $1500$ integers, and plot their empirical histogram. You can use the code fragment provided to generate the first $n$ factorials.\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans."
      ],
      "metadata": {
        "id": "YljDZzRgp_G8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77FZ8tmCb4GI"
      },
      "outputs": [],
      "source": [
        "#from scipy.misc import factorial\n",
        "#fact_series = factorial(np.arange(n),exact=True)\n",
        "#first_digit = np.zeros(n)\n",
        "#for i in range(n):\n",
        "# first_digit[i] = int(str(fact_series[i])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBT-fHg8b4GI"
      },
      "source": [
        "___\n",
        "**(b)** Use a Chi-square test to determine how well the data can be modeled using a uniform distribution.\n",
        "\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans."
      ],
      "metadata": {
        "id": "0cfhwR8NqeWa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehn4QDNZb4GI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okLmo5b2b4GI"
      },
      "source": [
        "___\n",
        "\n",
        "**(c)** Next, use a Chi-square test to test how well the data is modeled using the 'Benford's Law' distribution:\n",
        "$$p(d)= \\log _{10}(d+1)-\\log _{10}(d), \\quad d\\in\\{1,2,\\ldots,9\\}$$\n",
        "\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz3YDgLpb4GI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVl8W5m9b4GI"
      },
      "source": [
        "___\n",
        "\n",
        "**(d)** Finally, we will repeat this analysis with a more natural dataset. The dataset `us_pop.csv` contains the US population in 100,000 different zip codes in the year 2010, and the numbers range from less than ten to almost 100,000. As above, compute the histogram of the leading digits, and use the Chi-square test to see how well the data is modeled via the uniform and the Benford's law distributions.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ans."
      ],
      "metadata": {
        "id": "rKyZ12L2srUZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl7qScg0b4GI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(e) (Optional for all students)** To understand how the Benford's law distribution originates, the important idea is that when a random variable $X$ ranges over several orders (say between $0$ and $10^6$), then it is better modelled by saying that $\\log_{10}(X)$ is uniformly distributed on interval $[0,6]$ (rather than $X$ being uniform on $[0,10^6]$. Using this, can you derive the the exact probabilities for each of the leading digits."
      ],
      "metadata": {
        "id": "adS-uJlsuEPA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D3iMUEvEuRu8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}